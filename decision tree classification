from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import train_test_split
from sklearn.datasets import make_circles
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Generate synthetic data
X, y = make_circles(n_samples=1000, noise=0.05)

# Split data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Plot training data
sns.scatterplot(x=X_train[:, 0], y=X_train[:, 1], hue=y_train, palette='viridis', edgecolor='k')
plt.title("Train Data")
plt.show()

# Initialize and train the model
clf = MLPClassifier(max_iter=1000)
clf.fit(X_train, y_train)

# Print R2 scores for training and test data
print(f"R2 Score for Training Data = {clf.score(X_train, y_train)}")
print(f"R2 Score for Test Data = {clf.score(X_test, y_test)}")

# Predict on test data
y_pred = clf.predict(X_test)

# Plot predicted and actual test data
fig, ax = plt.subplots(1, 2, figsize=(12, 5))

# Plot predicted data
sns.scatterplot(x=X_test[:, 0], y=X_test[:, 1], hue=y_pred, palette='coolwarm', ax=ax[0], edgecolor='k')
ax[0].set_title("Predicted Data")

# Plot actual test data
sns.scatterplot(x=X_test[:, 0], y=X_test[:, 1], hue=y_test, palette='coolwarm', ax=ax[1], edgecolor='k')
ax[1].set_title("Test Data")

plt.show()
